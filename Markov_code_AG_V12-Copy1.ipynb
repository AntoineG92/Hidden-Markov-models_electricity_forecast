{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On particle filters applied to electricity load forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMC tuto\n",
    "\n",
    "https://pymc-devs.github.io/pymc/tutorial.html#fitting-the-model-with-mcmc\n",
    "\n",
    "http://sdsawtelle.github.io/blog/output/mcmc-in-python-with-pymc.html\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NC Email:\n",
    "\n",
    "Voilà quelques pistes que vous pouvez suivre:\n",
    "* commencer par implémenter un bootstrap filter pour le modèle proposé, et des valeurs des paramètres choisis à la main ﴾en fonction des valeurs reportées dans l'article par exemple﴿ et des données que vous pouvez simuler. Déterminer à quel point l'algorithme marche bien:\n",
    "+ graphe de l'ESS en fonction du temps; voir si effectivement certains outliers font fortement chuter l'ESS. Essayer la méthode proposée pour gérer ses outliers.\n",
    "+ intervalles de confiance pour l'estimation de E[X_t|Y_{0:t}], basé sur plusieurs exécutions, par exemple.\n",
    "\n",
    "Deuxième étape: estimation des paramètres. Vous pouvez essayer une des trois approches suivantes, triées par ordre de difficulté:\n",
    "1. maximisation de la vraisemblance ﴾estimée par votre filtre particulaire pour un theta donné﴿, en utilisant une méthode de maximisation pour fonction bruitée ﴾par ex Robbins‐Monroe﴿.\n",
    "2. PMMH, voir le prochain cours. Principale difficulté: l'algorithme peut prendre du temps, et ne pas être très facile à calibrer, mais je vais en parler en cours.\n",
    "3. Particle Gibbs: c'est peut‐être un peu compliqué pour ce modèle, mais si vous arrivez, gros bonus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib as mtp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.stats import truncnorm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import invgamma\n",
    "from scipy import ndimage\n",
    "import math\n",
    "\n",
    "### Parameters\n",
    "\n",
    "M=10**3 #number of particles\n",
    "n_pred=365  #number of predictions\n",
    "N_daytype=8  #number of day types\n",
    "\n",
    "### Load temperatures data 2015-2016\n",
    "\n",
    "df_temp=pd.read_csv('data/temp_1516.csv',sep=',')\n",
    "df_temp=df_temp.drop(df_temp.columns[0],axis=1)\n",
    "df_temp=df_temp.sort_values(by='date')\n",
    "df_temp.head()\n",
    "\n",
    "#temperatures every day at 3pm\n",
    "temp_day=df_temp[df_temp.hour==\"15:00\"]\n",
    "temp_day.head()\n",
    "#Array vector of temperatures for each day of the year\n",
    "T_h=list(temp_day.t)\n",
    "\n",
    "### Load electricity data\n",
    "\n",
    "mypath=\"data/\"\n",
    "df=pd.read_csv(mypath+\"cdc_conso_daytypes.csv\",sep=\",\",encoding='latin-1')\n",
    "df=df.drop([\"daytype\"+str(i) for i in range(0,9)],axis=1)\n",
    "df=df.drop(df.columns[0],axis=1)\n",
    "df.index=range(0,len(df))\n",
    "df=df.sort_values(by=['Date'])\n",
    "df['Date - Heure']=pd.to_datetime(df['Date - Heure'])\n",
    "df.sort_values(by=[\"Date - Heure\"])\n",
    "#truncate to the data from 2015\n",
    "df=df[(df.Date >='2015-01-01')]\n",
    "df.head()\n",
    "\n",
    "plt.plot_date(df.Date,df['Consommation (MW)'],fmt='-')\n",
    "plt.show()\n",
    "\n",
    "bins=range(30000,100000,1000)\n",
    "plt.hist(df['Consommation (MW)'],normed=True,bins=bins)\n",
    "plt.show()\n",
    "\n",
    "### Set variables of electricity demand\n",
    "\n",
    "from datetime import date\n",
    "df['Consommation']=df['Consommation (MW)']   #leave it in MW\n",
    "#For prediction, every day at 3pm\n",
    "consumption_day_ahead = list(df[df['Heure']=='15:00']['Consommation'])\n",
    "#for initialization\n",
    "consumption = list(df[df['Heure']=='15:00']['Consommation'][:30])\n",
    "\n",
    "## Implementation of Algorithm 3.10\n",
    "\n",
    "## At time n=0:\n",
    "\n",
    "### 1.Definition of MCMC initial model at n=0 - sample $X_0^{j} \\sim \\mu(x_0)$\n",
    "\n",
    "### Option A: Set values by hand\n",
    "\n",
    "#Add a bit of noise with uniform random\n",
    "#s=8000*np.ones(M)*npr.uniform(0.5,1.5,size=M)\n",
    "#sigma2_g_star=(10**5)*npr.uniform(0.5,1.5,size=M)\n",
    "#sigma2_s_star=(10**5)*npr.uniform(0.5,1.5,size=M)\n",
    "sigma_g_init=1.27*10**(8/2)\n",
    "sigma_s_init=(2*7.9)*10**3\n",
    "u_h=14 #mean of N(14,1)\n",
    "kappa=np.array([1/9]*9)\n",
    "sigma2=2.7*10**7\n",
    "g_heat_init = stats.truncnorm.rvs(-np.inf,0,loc=0,scale=10**4,size=M)\n",
    "s_init = stats.truncnorm.rvs(np.inf,0,loc=0,scale=10**4,size=M)\n",
    "sigma_s_star_2_evol=7.9*10**7\n",
    "sigma_g_star_2_evol=1.27*10**8\n",
    "\n",
    "x_init=x_season(df.daytype[15],kappa,s_init,sigma_s_init)[0]+x_heat(g_heat_init,15,sigma_g_init)[0]\n",
    "w_init= np.exp(-(np.square(consumption[15]-x_init))/(2*sigma2))\n",
    "\n",
    "### Option C: MCMC using MHA or Gibbs (TBA)\n",
    "\n",
    "#### Freeze parameters from Zak's simulation in gibbs-parameters_init_v1\n",
    "\n",
    "N_daytype=9\n",
    "k_day=npr.dirichlet(np.ones(N_daytype),1)\n",
    "len_init=15\n",
    "pred_forward=[0,1,2]\n",
    "\n",
    "#Load pickle file\n",
    "import pickle\n",
    "output_file ='data/parameters_init_20180113-135329.pkl'\n",
    "pkl_file = open(output_file, 'rb')\n",
    "parameters_init = pickle.load(pkl_file)\n",
    "parameters_init[\"x_init\"][:20]\n",
    "\n",
    "parameters_init\n",
    "\n",
    "s_init=parameters_init['s_init']\n",
    "g_heat_init=parameters_init['g_heat_init']\n",
    "sigma_s_init=parameters_init['sigma_s_init']\n",
    "sigma_g_init=parameters_init['sigma_g_init']\n",
    "x_init=parameters_init['x_init']\n",
    "sigma2=parameters_init['sigma2']\n",
    "u_h=parameters_init['u_h']\n",
    "kappa=parameters_init['kappa']\n",
    "w_init=parameters_init['w_init']\n",
    "\n",
    "sigma2=np.ones(M)*3*10**7\n",
    "sigma_g_init=np.ones(M)*10**4\n",
    "sigma_s_init=np.ones(M)*10**4\n",
    "kappa=np.ones(M)*1/9\n",
    "\n",
    "w_init[0]=np.median(w_init)\n",
    "x_init[0]=np.median(x_init)\n",
    "g_heat_init[0]=np.median(g_heat_init)\n",
    "s_init[0]=np.median(s_init)\n",
    "\n",
    "### Part 2: regularize weights and x if necessary\n",
    "\n",
    "#STEP 2 OF PARTICLE FILTER\n",
    "def resample(x_pred,w_prev,nbdays_pred_today,len_init,n,sigma_s,sigma_g,g_h,s,sigma,ESS):   \n",
    "    #compute y_n\n",
    "    delta_cons_gaus=-np.square(consumption_day_ahead[len_init+n+nbdays_pred_today]-x_pred)/(2*sigma**2)\n",
    "    y_n=np.exp(delta_cons_gaus)\n",
    "    #compute new weights\n",
    "    if n>0:\n",
    "        w_=w_prev*y_n\n",
    "    else:\n",
    "        w_=w_prev\n",
    "    #likelihood of y_n\n",
    "    lh_y_n=np.sum(delta_cons_gaus)\n",
    "    #normalize weights\n",
    "    w_h=w_/sum(w_)\n",
    "    #calculate ESS\n",
    "    ESS=1/sum(np.square(w_h))\n",
    "    x =np.zeros(M)\n",
    "    w =np.zeros(M)\n",
    "    print(\"ESS of normalized weights=\",round(ESS,6))\n",
    "    if ESS <0.001*M: #reset the weights, keep x predicted as such\n",
    "        print(\"ESS <0.001*M\")\n",
    "        x=x_pred\n",
    "        if n==0:\n",
    "            w=np.ones(M)*(1/M)\n",
    "        w=w_prev\n",
    "    elif (ESS>=0.001*M and ESS<0.5*M):  #reset all the weights, add some noise to a fraction of the x's\n",
    "        print(\"ESS>=0.001*M and ESS_0<0.5*M\")\n",
    "        x,w,sigma_s,sigma_g,g_h,s=resample_multinomial(x_pred,w_h,sigma_s,sigma_g,g_h,s)\n",
    "    elif ESS>=0.5*M:  #No degeneracy\n",
    "        print(\"ESS>=0.5*M\")\n",
    "        x=x_pred\n",
    "        w=w_h\n",
    "    else:\n",
    "        print(\"ESS critically low\")\n",
    "        x=x_pred\n",
    "        if n==0:\n",
    "            w=np.ones(M)*(1/M)\n",
    "        w=w_prev\n",
    "            \n",
    "    print(\"new ESS=\",round(1/sum(np.square(w)),6))\n",
    "    return x,w,ESS,lh_y_n,sigma_s,sigma_g,g_h,s\n",
    "\n",
    "def resample_multinomial(x_temp,w_temp,sigma_s,sigma_g,g_h,s):\n",
    "    multinomial = np.random.multinomial(1,w_temp,M)\n",
    "    new_x = np.zeros(M)\n",
    "    new_s = np.zeros(M)\n",
    "    new_g_heat = np.zeros(M)\n",
    "    new_sigma_s = np.zeros(M)\n",
    "    new_sigma_g = np.zeros(M)\n",
    "    for i in range(M):\n",
    "        new_x[i]=x_temp[np.argmax(multinomial[i,])]\n",
    "        new_s[i]=s[np.argmax(multinomial[i,])]\n",
    "        new_g_heat[i]=g_h[np.argmax(multinomial[i,])]\n",
    "        new_sigma_s[i]=sigma_s[np.argmax(multinomial[i,])]\n",
    "        new_sigma_g[i]=sigma_g[np.argmax(multinomial[i,])]\n",
    "    new_w=(1/M)*np.ones(M)   \n",
    "    return new_x,new_w,new_sigma_s,new_sigma_g,new_g_heat,new_s\n",
    "\n",
    "#initialize matrix of x_heat, x_season\n",
    "ESS=np.array(np.ones(n_pred+1))\n",
    "x =np.zeros([n_pred+1,M])\n",
    "w =np.zeros([n_pred+1,M])\n",
    "lh_y_n =np.zeros(n_pred+1)\n",
    "x_season =np.zeros([n_pred+1,M]) \n",
    "x_heat =np.zeros([n_pred+1,M])\n",
    "\n",
    "x[0,:],w[0,:],ESS[0],lh_y,sigma_s_init,sigma_g_init,g_heat_init,s_init=resample(x_init,w_init,2,15,0,sigma_s_init,\n",
    "                                                                                sigma_g_init,\n",
    "                                                                                g_heat_init,s_init,sigma2**0.5,ESS)\n",
    "\n",
    "## Prediction and Filtering at time n>0\n",
    "\n",
    "### 1. Sample $x^j_n \\mid X^j_{n-1} $ for all j=1...M particles\n",
    "\n",
    "def x_season(day_type,k_day,s_prev,sigma_s_prev):\n",
    "    nu=truncnorm.rvs(a = (-sigma_s_prev-0) / sigma_g_init , b = np.inf, loc= 0, scale = sigma_g_init, size=M)\n",
    "    sigma_s=sigma_s_prev+nu\n",
    "    err=truncnorm.rvs(a = -s_prev / sigma_s , b = np.inf, loc= 0, scale = sigma_s, size=M)\n",
    "    s=s_prev+err\n",
    "    x_s=s*k_day[day_type]\n",
    "    return x_s, s, sigma_s\n",
    "\n",
    "def x_heat(g_h_prev,day,sigma_g_prev):\n",
    "    nu=truncnorm.rvs(a = -sigma_g_prev / sigma_g_init , b = np.inf, loc= 0, scale = sigma_g_init, size=M)\n",
    "    sigma_g=sigma_g_prev+nu\n",
    "    err=truncnorm.rvs(a = -np.inf , b =(-g_h_prev-0) / sigma_g, loc= 0, scale = sigma_g, size=M)\n",
    "    g_h=g_h_prev+err\n",
    "    if(u_h-T_h[day]<0):\n",
    "        print(\"No heating effect\")\n",
    "    x_h=g_h*(T_h[day]-u_h)*max(np.sign(u_h-T_h[day]),0)\n",
    "    return x_h, g_h, sigma_g\n",
    "\n",
    "daytype=np.array(df.daytype)\n",
    "\n",
    "print(x_season(daytype[15],kappa,s_init,sigma_s_init)[2])\n",
    "print(x_heat(g_heat_init,16,sigma_g_init)[2])\n",
    "\n",
    "#Initialize parameters\n",
    "def particle_filter(nbdays_pred_today,len_init,len_filtering,s,g_h,sigma_s,sigma_g,sigma,lh_y):\n",
    "    lh_y_n=np.zeros(len_filtering)\n",
    "    x_pred=np.zeros([len_filtering,M])\n",
    "    x_pred_mean=np.zeros(len_filtering)\n",
    "    ESS=np.zeros(len_filtering)\n",
    "    for n in range(1,len_filtering):\n",
    "        print(\"n=\",n)\n",
    "        #prediction X[n] one day ahead, hourly forecast\n",
    "        x_s=x_season(int(daytype[len_init+n+nbdays_pred_today]),kappa,s,sigma_s)\n",
    "        x_h=x_heat(g_h,n+len_init+nbdays_pred_today,sigma_g)\n",
    "        x_pred[n,:]=x_s[0]+x_h[0]\n",
    "        #print(\"number of negative values:\",len(x_pred[x_pred<0]))\n",
    "        print(\"x_pred_mean =\",\"{:.2e}\".format(np.mean(x_pred[n,:])),\n",
    "              \"real consumption=\",\"{:.2e}\".format(consumption_day_ahead[n]))\n",
    "        print(\"x_pred min=\",\"{:.2e}\".format(np.min(x_pred[n,:])),\"x_pred max\",\"{:.2e}\".format(np.max(x_pred[n,:])))\n",
    "        #take new values of parameters to feed x_season and x_heat in the next step\n",
    "        s, sigma_s=x_s[1:]\n",
    "        g_h, sigma_g=x_h[1:]\n",
    "        #regularization\n",
    "        x[n,:],w[n,:],ESS[n],lh_y_n[n],sigma_s,sigma_g,g_h,s=resample(x_pred[n,:],w[n-1,:],nbdays_pred_today,len_init,n,sigma_s,sigma_g,g_h,s,sigma,ESS)\n",
    "        print(\"------------------------\")\n",
    "        x_pred_mean[n]=np.mean(x_pred[n,:])\n",
    "    return lh_y_n,x_pred_mean,ESS\n",
    "\n",
    "x_predict=np.zeros([len(pred_forward),n_pred])\n",
    "ESS_calc=np.zeros([len(pred_forward),n_pred])\n",
    "for i in range(len(pred_forward)):\n",
    "    log_lh_init,x_predict[i,:],ESS_calc[i,:]=particle_filter(pred_forward[i],len_init,n_pred,s_init,g_heat_init,sigma_s_init,sigma_g_init,sigma2**0.5,lh_y_n)\n",
    "\n",
    "fig=plt.figure(figsize=(12,6))\n",
    "plt.plot(range(1,n_pred),ESS_calc[0,1:n_pred]/M)\n",
    "plt.plot(range(1,n_pred),ESS_calc[1,1:n_pred]/M)\n",
    "plt.plot(range(1,n_pred),ESS_calc[2,1:n_pred]/M)\n",
    "\n",
    "plt.title(\"Evolution of ESS\",fontweight='bold')\n",
    "plt.xlabel('forecasted day')\n",
    "plt.xlim(0,n_pred)\n",
    "plt.show()\n",
    "\n",
    "fig=plt.figure(figsize=(12,6))\n",
    "\n",
    "\n",
    "plt.plot(range(n_pred),(x_predict[0,:]-consumption_day_ahead[:n_pred])/consumption_day_ahead[:n_pred],color='blue')\n",
    "plt.plot(range(n_pred),(x_predict[1,:]-consumption_day_ahead[1:n_pred+1])/consumption_day_ahead[1:n_pred+1],color='orange')\n",
    "plt.plot(range(n_pred),(x_predict[2,:]-consumption_day_ahead[2:n_pred+2])/consumption_day_ahead[2:n_pred+2],color='green')\n",
    "\n",
    "plt.plot(range(n_pred-1),np.zeros(n_pred-1),color='red',linestyle='--')\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(0,n_pred)\n",
    "plt.xlabel('forecasted day')\n",
    "plt.title(\"Relative forecast error\",fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "fig=plt.figure(figsize=(12,6))\n",
    "plt.plot(range(n_pred),x_predict[0,:])\n",
    "plt.plot(range(n_pred),x_predict[1,:])\n",
    "plt.plot(range(n_pred),x_predict[2,:])\n",
    "plt.plot(range(n_pred),consumption_day_ahead[:n_pred],linestyle='--')\n",
    "plt.xlabel('forecasted day')\n",
    "plt.ylim(10**4,10**5)\n",
    "plt.title(\"Electricity load forecast in W\",fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "Goal: re-estimate the one-dimensional parameters ($\\sigma_g,\\sigma_s,\\mu_h,\\kappa,\\sigma$)<br>\n",
    "Proposal distribution for these parameters: truncated gaussian random walk<br>\n",
    "We set kappa constant at 1/8\n",
    "\n",
    "\n",
    "\n",
    "## PMMH\n",
    "\n",
    "#### Initialization of parameters\n",
    "\n",
    "u_h_current=13\n",
    "sigma_current=10**4\n",
    "sigma_g_current=10**4\n",
    "sigma_s_current=10**4\n",
    "\n",
    "len_filter_pmmh=365\n",
    "len_iter_mha=2\n",
    "accept_log_proba=np.zeros(len_filter_pmmh)\n",
    "accept_rate=0\n",
    "log_lh_init=np.zeros(len_filter_pmmh)\n",
    "lh_y_prop=np.zeros(len_filter_pmmh)\n",
    "\n",
    "#store the accepted value in lists\n",
    "u_h_list=[]\n",
    "sigma_list=[]\n",
    "sigma_g_list=[]\n",
    "sigma_s_list=[]\n",
    "\n",
    "#### Initialization of hyperparameters\n",
    "\n",
    "#standard deviation of normal/trunc normal proposals on parameters\n",
    "std_hyp_sigma_g,std_hyp_sigma_s,std_hyp_sigma=np.ones(3)*5*10**3\n",
    "std_hyp_u=1\n",
    "\n",
    "#joint prior density of parameters\n",
    "def log_joint_prior(u_h,sigma,sigma_g,sigma_s):\n",
    "    res=0\n",
    "    res=(-(u_h-14)**2)/2\n",
    "    res=res+(-0.01-1)*np.log(sigma**2) - (0.01/sigma**2)\n",
    "    res=res+(-0.01-1)*np.log(sigma_g**2) - (0.01/sigma_g**2)\n",
    "    res=res+(-0.01-1)*np.log(sigma_s**2) - (0.01/sigma_s**2)\n",
    "    return res\n",
    "\n",
    "#joint log prior density initialize\n",
    "log_prior_init=log_joint_prior(u_h_current,sigma_current,sigma_g_current,sigma_s_current)\n",
    "print(log_prior_init)\n",
    "#initial parameters otbained from Gibbs. These initialized parameters will not change through iterations\n",
    "\n",
    "#### Run initial particle filter and get the log likelihood\n",
    "\n",
    "log_lh_init=particle_filter(pred_forward[0],len_init,len_filter_pmmh,s_init,g_heat_init,sigma_s_current,sigma_g_current,sigma_current,lh_y_n)[0]\n",
    "\n",
    "print(log_lh_init[len_filter_pmmh-1])\n",
    "\n",
    "#### PMMH Algorithm\n",
    "\n",
    "for step in range(len_iter_mha):\n",
    "    print(\"___________________________________________________________\")\n",
    "    print(\"Metropolis Hastings step:\",step)\n",
    "    #we need 6 inputs to compute the (log) acceptance probability log(r):\n",
    "    #log_likelihood, joint prior density, log proposal density for both current parameters and proposed parameters\n",
    "    #sample proposal for u_h, sigma, sigma_g, sigma_s\n",
    "    u_h_prop=npr.normal(u_h_current,std_hyp_u,size=1)\n",
    "    sigma_prop=stats.truncnorm.rvs(a=(0-sigma_current)/std_hyp_sigma,b=np.inf,scale=std_hyp_sigma,size=1)\n",
    "    sigma_g_prop=stats.truncnorm.rvs(a=(0-sigma_g_current)/std_hyp_sigma_g,b=np.inf,scale=std_hyp_sigma_g,size=1)\n",
    "    sigma_s_prop=stats.truncnorm.rvs(a=(0-sigma_s_current)/std_hyp_sigma_s,b=np.inf,scale=std_hyp_sigma_s,size=1)\n",
    "    print(\"proposed parameters:\",\"u_heat:\",u_h_prop,\"sigma:\",sigma_prop,\"sigma_g:\",sigma_g_prop,\"sigma_s:\",sigma_s_prop)\n",
    "    #1/run a particle filter with the proposed parameters to obtain a an estimation of likelihood proposed\n",
    "    #  consider the likelihood of the last day of the fitering\n",
    "    lh_y_prop=particle_filter(pred_forward[0],len_init,len_filter_pmmh,s_init,g_heat_init,sigma_s_prop,sigma_g_prop,sigma_prop,lh_y_n)[0]\n",
    "    print(\"log likelihood proposal of y:\",np.sum(lh_y_prop))\n",
    "    #2/generate prior proposals and compute joint log density of them\n",
    "    log_prior_prop = log_joint_prior(u_h_prop,sigma_prop,sigma_g_prop,sigma_s_prop)\n",
    "    print(\"proposed log prior:\",log_prior_prop)\n",
    "    #3/compute log proposal density h(current parameter|proposed parameter)\n",
    "    current_log_density=np.log(stats.norm.cdf(sigma_current/std_hyp_sigma,loc=0,scale=1))+np.log(\n",
    "        stats.norm.cdf(sigma_s_current/std_hyp_sigma_s,loc=0,scale=1))+np.log(\n",
    "        stats.norm.cdf(sigma_g_current/std_hyp_sigma_g,loc=0,scale=1))\n",
    "    print(\"proposal log density initial parameters given proposed param:\",current_log_density)\n",
    "    #4/log likelihood from initial parameters --> already done: log_lh_init\n",
    "    #5/joint prior of the initial parameters: we already have them\n",
    "    #6/compute log proposal density h(proposed parameter|current parameter)\n",
    "    prop_log_density=np.log(stats.norm.cdf(sigma_prop/std_hyp_sigma,loc=0,scale=1))+np.log(\n",
    "    stats.norm.cdf(sigma_s_prop/std_hyp_sigma_s,loc=0,scale=1))+np.log(\n",
    "    stats.norm.cdf(sigma_g_prop/std_hyp_sigma_g,loc=0,scale=1))\n",
    "    print(\"proposal log density proposed parameters given current param:\",prop_log_density)\n",
    "    #we add up these elements to construct the log acceptance probability\n",
    "    #numerator\n",
    "    accept_log_proba[step]=np.sum(lh_y_prop)+log_prior_prop+current_log_density\n",
    "    #denominator\n",
    "    accept_log_proba[step]=accept_log_proba[step]-np.sum(log_lh_init)-log_prior_init-prop_log_density\n",
    "    print(\"acceptance log probability:\",accept_log_proba[step])\n",
    "    u=npr.random()\n",
    "    #to get an acceptance rate > 5%, we need log_proba to be at least -3\n",
    "    if(np.log(u)<min(0,accept_log_proba[step])):\n",
    "        print(\"ACCEPT\")\n",
    "        accept_rate=accept_rate+1\n",
    "        log_lh_init=lh_y_prop\n",
    "        sigma_current=sigma_prop\n",
    "        sigma_g_current=sigma_g_prop\n",
    "        sigma_s_current=sigma_s_prop\n",
    "        u_h_current=u_h_prop\n",
    "        #store the accepted values\n",
    "        u_h_list.append(u_h_current)\n",
    "        sigma_list.append(sigma_current)\n",
    "        sigma_g_list.append(sigma_g_current)\n",
    "        sigma_s_list.append(sigma_s_current)\n",
    "    else:\n",
    "        print(\"REJECT\")\n",
    "\n",
    "print(accept_rate/len_iter_mha)\n",
    "\n",
    "print(sigma_current)\n",
    "print(sigma_g_current)\n",
    "print(sigma_s_current)\n",
    "print(u_h_current)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
